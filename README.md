<div>

### Подготовка данных

Скрипт prepare_data.py распаковывает архив с аудио данными в корневую папку проекта.

### Анализ метаданных файлов
#### Подготовка метаданных
Скрипт preprocessing/create_audio_metadata_csv.py читает все аудиофайлы и 
составляет csv файл со следующими колонками: 
<ul>
    <li>Идентификатор эмоции (название директории)</li> 
    <li>Название файла</li>
    <li>Кол-во каналов аудио</li>
    <li>Размер одного сэмпла в байтах</li>
    <li>Частота дискретизации</li>
    <li>Кол-во сэмплов в файле (продолжительность аудио деленная на частоту дискретизации)</li>
    <li>Тип сжатия файла</li>
    <li>Человекочитаемое название алгоритма сжатия</li>
</ul> 

#### Анализ метаданных

В заметке notebooks/audio_metadata_analysis.ipynb 
представлен анализ вышеперечисленных метаданных аудиофайлов.
<br><br>
В ходе анализа было выяснено, что все файлы несжаты, имеют одинаковую частоту дискретизации,
одинаковый размер сэмлов, но разное количество сэмлов 
(что достаточно логично при том условии, что продолжительность всех файлов разная). Чтобы иметь
представление о распределении количества сэмплов в аудиофайлах, были посчитаны следующие 
характеристики:
<ul>
    <li>Среднее значение</li>
    <li>Стандартное отклонение</li>
    <li>Минимальное кол-во сэмплов</li>
    <li>Максимально кол-во сэмплов</li>
    <li>Кол-во файлов, образующих: 
        <ul>
            <li>топ 25% самых коротких по количеству сэмлов</li>
            <li>топ 50% самых коротких по количеству сэмлов</li>
            <li>топ 75% самых коротких по количеству сэмлов</li>
        </ul>
</ul>
<br>
Отдельно можно отметить, что у трех файлов был стерео формат. Эти файлы при обработке
конвертируются в моно.

<br>

#### Итог анализа метаданных

По итогу анализа сложилось впечатление о достаточной однородности файлов, 
не требущей какой-либо специальной дополнительной обработка.

### Извлечение фич из данных

#### Исследование аудиоданных

В заметке notebook/spectrogram_analysis.ipynb представлен
анализ аудиоданных.
<br>

В качестве примера было взято по 3 файлов из каждой категории.
Для каждого из них был построены waveplot (график уровня звука от времени), 
изображение спектрограммы, графики зависимости спектральной ширины, 
спектрального центроида,
спектрального спада, частоты пересечения нуля от времени.
Эти же фичи мы выбрали для обучения модели.
<br>

Стоит отметить, что по скольку все данные имеют разное количество сэмлов, пришлось
поколдовать над параметрами дискретного преобразования Фурье и изменить 
параметры window_size и hop_length так, чтобы на выходе преобразования получились одинаковые
размерности массивов фич over time. 
<br>

С помощью скрипта create_normilized_audio_spec_images.py и заметки
create_one_csv_from_many.ipynb был сформирован единый csv файл 
с вышеперечисленными фичами.

### Обучение
#### Модель #1

В качестве первой модели была выбрана обычная Dense Neural Network
с 2-3 слоями. Известно, что такие сети не очень хорошо работают с временными рядами,
однако по исходным данным задача показалась
очень похожей на задачу о классификации изображений цифр на датасете MNIST. 
(хотя также известно, что DNN - не самый лучший способ анализировать изображения).
С последней задачей DNN может справляться с вероятностью около 92%.
Схожесть по исходным данным заключалась в том, что формат исходных данных одинаков: в MNIST - 
черное белые изображения 28х28, в нашей задаче - одна и та же фраза (с погрешностью), одна и 
таже продолжительность (около 3 сек, также с порешностью) и вера в то, что особенности
различных голосов не сильно должны повлиять на результат.

<br>
Реализация модели представлена в заметке models/dense_nn.ipynb. 
После некоторого тюнинга параметров было выяснено, что лучше всего работает
сеть с двумя слоями: input(172) -> dense(100) -> dense(5). Такая сеть показывает на тестовой 
выборке value_categorical_accuracy - (0.37-0.40), что лучше, чем наугад, почти в 2 раза. :)

<br>

##### Вывод по модели #1
Имея абсолютную уверенность, что с текущей задачей DNN обязана справляться еще как минимум в 
два раза лучше, была выдвинута гипотеза о том, что либо были выбраны не самые показательные
фичи, либо неудачно нормализованы. К сожалению, цейтнот не позволил проверить нам эту гипотезу.

#### Модель #2 (безнадежная, но очень уж хотелось попробовать)

В качестве эксперимента "из любопытства" была реализована сверточная нейронная сеть,
которой скармливалась голая спектрограмма. Очевидно, что для такой задачи CNN - ~~стрельба 
из пушки~~ сброс ядерных бомб на воробьев (чего уж мелочится, бедные воробьи), так как фич у нас мало, данных - мало, подход абсолютно
 немногообещающий, но любопыство взяло верх. 
 
<br>
Первоначальной идеей было было скормить изображение спектрограммы, однако немного порассуждав,
было принято решение скормить матрицу результата дискретного преобразования Фурье, 
взяв только амлитуды гармоник конечно же, ведь по сути, изображение несло бы информации не битом больше,
чем наша матрица, однако накладывало на несколько порядков тренируемых коэффициентов больше.

<br>
Создав модель и взглянув ее summary (заметка models/cnn.ipynb), стало совсем очевидно, что затея - бред сумашедшего: 
аудио файлов для тренировки - 659, 
а фич в каждом файле примерно 360 тысяч.

<br>
Сеть из двух сверточных слоев с average пулингом, flatten слоя и dense(5) слоя сыграла в угадайку 
с результатом categorical_accuracy - 0.2. Также абсолютно не исключено, что при построении сети, была
допущена ошибка (а то и не одна)

<br>

##### Вывод по модели #2
Чисто теоретически, если рассматривать сверточную нейронную сеть в терминах паттернов Хаара, то
чисто гипотетически при достаточном количестве исходных данных и выше описанном подходе должно получится
что-то стоящее, но это уже совсем другая история...

### Вывод по проделанной работе

Приняв DNN за панацею и посчитав (возможно, наивно), 
что если сеть не справится, 
то ни один из классических методов по извлеченным нами фичам не справится, а также принять в расчет, что
отсутствие результата - тоже результат, был сделан вывод, что по среди наших фич есть те, по которым можно определить
эмоцию, но либо недостаточно самих фич, либо проведена недостаточная предобработка.  


</div>
